---
author: "Ben Wallace"
title: "Memo 1: COVID-19"
date: "February 20, 2022"
---



As the COVID Tracking project and The *New York Times* makes clear, collecting counts of COVID-19 cases, deaths, and hospitalizations is not an easy task. Before the onset of the pandemic in the spring of 2020, the United States was not prepared to manage such data. First, each state varied in both their choice of data collection and reporting. Many also changed their methods over time. "[The quantity of data increased over the pandemic, but states continued to struggle with quality](https://covidtracking.com/analysis-updates/why-we-didnt-automate-our-data-collection)," Jonathan Gilmour writes. Second, this challenge has permeated federal agencies as well, such as the CDC, requiring them to rely laboratory case counts in the absence of state-level data. Beyond the federal government, organizations have also altered their data collection techniques to accommodate a patchwork system. Rather than relying simply on automated systems that monitor state dashboards, the COVID-19 Tracking project manually inputs data.

Analyses by journalists and data scientists have complicated my understanding of how the "[statistic state](https://www.cambridge.org/core/journals/comparative-studies-in-society-and-history/article/abs/statistics-and-the-modern-state/2E11AE70F4B1DA7E705307170B708FE9)" operates in an increasingly data-driven world. In the past, I have taken interest in how the federal government tracks hate crimes, a task which similarly struggles with a patchwork system of data collection and publication. Some local law enforcement agencies simply don't report hate crime counts or do so inadequately, leading the government to rely on inferencing  much in the same manner as the CDC handles COVID-19 information. Then, there are federal guidelines, such as the definition of hate crimes and which variables to collect, and the lofty assumption that all branches of government will respect them. As the COVID-19 and hate crime cases both trouble my understanding of large-scale data efforts, I wonder how the federal government can discuss their limitations and improve transparency. Quoted by the *[New York Times](https://www.nytimes.com/2022/02/17/briefing/coronavirus-what-happened-today-boosters.html)*,  Dr. Peter Marks from the FDA argues that their future pandemic responses, like whether to recommend a fourth dose of the vaccine, are hampered by data collection difficulties. What does it mean to be more transparent about the government's shortcomings in an era of eroding institutional trust? Which junctures of history have left us so ill-prepared to handle national data reporting? Optimistically, I believe that transparent deliberations about the histories and struggles that government officials face would begin to repair the distrust seeded in public discourse today.